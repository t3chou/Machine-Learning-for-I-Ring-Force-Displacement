# 9. Result

It is definitely <mark style="background-color:red;">not the ultimate result</mark>, because the number fail data is still too small for robust prediction. As a result, the result here is just to illustrate the data we have so far, and its performance still needs some improvements. It will not be too difficult to make it better once the system can collect more fail data or someone goes to conduct more experiments to produce fail data.

Patch number means that because we trained the data before and store the scaler then, so batch number n presents that we use scaler n to modify the data and then put the data into 105 models, and then add the result up to check the answer is more than 50 or not. If the answer is bigger than 50, we identify that data would be successful, vise versa.

Here, it is shown on the table that the accuracy(the ability to distinguish the prediction of the result) of each batch can provide.

| Batch Number | Accuracy | Description |
| :----------: | :------: | :---------: |
|       1      |  0.93645 |             |
|       2      |  0.91051 |             |
|       3      |  0.93515 |             |
|       4      |  0.87678 |             |
|       5      |  0.89624 |             |
|       6      |  0.81193 |             |
|       7      |  0.84565 |             |
|       8      | 0.782101 |             |
|       9      |  0.7808  |    LOWEST   |
|      10      |  0.93774 |   HIGHEST   |
|      11      | 0.910506 |             |
|      12      |  0.89364 |             |
|      13      |  0.85992 |             |
|      14      |  0.81971 |             |
|      15      |  0.79377 |             |

To sum up, in the phase of training, we have checked each classifiers can provide the accuracy over 0.7 in a chunk. And the table above is to show the ability of each chunk can perform.
